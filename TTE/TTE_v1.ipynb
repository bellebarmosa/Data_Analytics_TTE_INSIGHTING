{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TTE_v1: Convert R Codes into Python**\n",
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP Trial Directory: /var/folders/j1/98lnr0rj7px6w8q4b_d6mlmm0000gn/T/trial_pp\n",
      "ITT Trial Directory: /var/folders/j1/98lnr0rj7px6w8q4b_d6mlmm0000gn/T/trial_itt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Define estimands as variables\n",
    "trial_pp_estimand = \"PP\"   # Per-protocol\n",
    "trial_itt_estimand = \"ITT\"  # Intention-to-treat\n",
    "\n",
    "# Create directories to save files\n",
    "trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "print(f\"PP Trial Directory: {trial_pp_dir}\")\n",
    "print(f\"ITT Trial Directory: {trial_itt_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "{'Estimand': 'ITT', 'Observations': 725, 'Patients': 89, 'Columns': ['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s', 'outcome', 'censored', 'eligible'], 'Sample Data':    id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  }\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset \n",
    "data_censored = pd.read_csv(\"../data/data_censored.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(data_censored.head())\n",
    "\n",
    "# Define a function to structure the trial data\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        self.estimand = estimand\n",
    "        self.data = data\n",
    "        self.id_col = id_col\n",
    "        self.period_col = period_col\n",
    "        self.treatment_col = treatment_col\n",
    "        self.outcome_col = outcome_col\n",
    "        self.eligible_col = eligible_col\n",
    "\n",
    "    def summary(self):\n",
    "        return {\n",
    "            \"Estimand\": self.estimand,\n",
    "            \"Observations\": self.data.shape[0],\n",
    "            \"Patients\": self.data[self.id_col].nunique(),\n",
    "            \"Columns\": self.data.columns.tolist(),\n",
    "            \"Sample Data\": self.data.head()\n",
    "        }\n",
    "\n",
    "# Create the Per-Protocol (PP) trial sequence\n",
    "trial_pp = TrialSequence(\n",
    "    estimand=\"PP\",\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Create the Intention-to-Treat (ITT) trial sequence\n",
    "trial_itt = TrialSequence(\n",
    "    estimand=\"ITT\",\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Print a summary of the ITT trial\n",
    "print(trial_itt.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Weight models and censoring**\n",
    "\n",
    "To adjust for the effects of informative censoring, inverse probability of censoring weights (IPCW) can be applied. To estimate these weights, we construct time-to-(censoring) event models. Two sets of models are fit for the two censoring mechanisms which may apply: censoring due to deviation from assigned treatment and other informative censoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Censoring due to treatment switching**\n",
    "\n",
    "We specify model formulas to be used for calculating the probability of receiving treatment in the current period. Separate models are fitted for patients who had treatment = 1 and those who had treatment = 0 in the previous period. Stabilized weights are used by fitting numerator and denominator models.\n",
    "\n",
    "There are optional arguments to specify columns which can include/exclude observations from the treatment models. These are used in case it is not possible for a patient to deviate from a certain treatment assignment in that period.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               eligible   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.09696\n",
      "Time:                        16:39:33   Log-Likelihood:                -356.57\n",
      "converged:                       True   LL-Null:                       -394.86\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.120e-18\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.9822      0.383      5.180      0.000       1.232       2.732\n",
      "age           -0.0692      0.008     -8.152      0.000      -0.086      -0.053\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def fit_logistic_regression(data, numerator, denominator, save_path):\n",
    "    \"\"\"\n",
    "    Fits a logistic regression model using statsmodels.\n",
    "\n",
    "    :param data: Pandas DataFrame containing the dataset.\n",
    "    :param numerator: Formula string for the numerator (predictor variables).\n",
    "    :param denominator: Formula string for the denominator (predictor variables).\n",
    "    :param save_path: Path to save the trained model.\n",
    "    :return: Fitted logistic regression model.\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=numerator + denominator)  # Remove missing values\n",
    "\n",
    "    # Fit the numerator model (logistic regression)\n",
    "    X_num = sm.add_constant(data[numerator])  # Add intercept\n",
    "    y_num = data['eligible']  # Assuming eligibility is the binary outcome variable\n",
    "    model_num = sm.Logit(y_num, X_num).fit(disp=False)\n",
    "\n",
    "    # Fit the denominator model (logistic regression)\n",
    "    X_denom = sm.add_constant(data[denominator])\n",
    "    model_denom = sm.Logit(y_num, X_denom).fit(disp=False)\n",
    "\n",
    "    # Save models\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump({\"numerator_model\": model_num, \"denominator_model\": model_denom}, f)\n",
    "\n",
    "    return model_num, model_denom\n",
    "\n",
    "# Define the predictor variables\n",
    "numerator_vars = [\"age\"]\n",
    "denominator_vars = [\"age\", \"x1\", \"x3\"]\n",
    "\n",
    "# Define file path for saving the model\n",
    "switch_model_path = os.path.join(trial_pp_dir, \"switch_models.pkl\")\n",
    "\n",
    "# Fit the switch weight model and save it\n",
    "trial_pp.switch_weights = fit_logistic_regression(\n",
    "    trial_pp.data,\n",
    "    numerator=numerator_vars,\n",
    "    denominator=denominator_vars,\n",
    "    save_path=switch_model_path\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(trial_pp.switch_weights[0].summary())  # Summary of the numerator model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Other informative censoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        16:39:36   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.4481      0.141    -17.415      0.000      -2.724      -2.173\n",
      "x2             0.4486      0.137      3.278      0.001       0.180       0.717\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def fit_censor_weight_model(data, censor_event, numerator, denominator, save_path):\n",
    "    \"\"\"\n",
    "    Fits a logistic regression model for censoring weights.\n",
    "\n",
    "    :param data: Pandas DataFrame containing the dataset.\n",
    "    :param censor_event: Column name indicating whether an event was censored.\n",
    "    :param numerator: List of predictor variables for the numerator model.\n",
    "    :param denominator: List of predictor variables for the denominator model.\n",
    "    :param save_path: Path to save the trained models.\n",
    "    :return: Tuple of fitted logistic regression models (numerator, denominator).\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=numerator + denominator + [censor_event])  # Remove missing values\n",
    "\n",
    "    # Fit the numerator model (logistic regression)\n",
    "    X_num = sm.add_constant(data[numerator])  # Add intercept\n",
    "    y_num = data[censor_event]  # Assuming 'censored' is a binary column (1 = censored, 0 = not censored)\n",
    "    model_num = sm.Logit(y_num, X_num).fit(disp=False)\n",
    "\n",
    "    # Fit the denominator model (logistic regression)\n",
    "    X_denom = sm.add_constant(data[denominator])\n",
    "    model_denom = sm.Logit(y_num, X_denom).fit(disp=False)\n",
    "\n",
    "    # Save models\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump({\"numerator_model\": model_num, \"denominator_model\": model_denom}, f)\n",
    "\n",
    "    return model_num, model_denom\n",
    "\n",
    "# Define the predictor variables\n",
    "numerator_vars = [\"x2\"]\n",
    "denominator_vars = [\"x2\", \"x1\"]\n",
    "\n",
    "# Define file path for saving the model\n",
    "censor_model_path = os.path.join(trial_pp_dir, \"censor_models.pkl\")\n",
    "\n",
    "# Fit the censor weight model and save it\n",
    "trial_pp.censor_weights = fit_censor_weight_model(\n",
    "    trial_pp.data,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=numerator_vars,\n",
    "    denominator=denominator_vars,\n",
    "    save_path=censor_model_path\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(trial_pp.censor_weights[0].summary())  # Summary of the numerator model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        16:39:39   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.4481      0.141    -17.415      0.000      -2.724      -2.173\n",
      "x2             0.4486      0.137      3.278      0.001       0.180       0.717\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def fit_censor_weight_model(data, censor_event, numerator, denominator, save_path, pool_models=\"numerator\"):\n",
    "    \"\"\"\n",
    "    Fits a logistic regression model for censoring weights.\n",
    "\n",
    "    :param data: Pandas DataFrame containing the dataset.\n",
    "    :param censor_event: Column name indicating whether an event was censored.\n",
    "    :param numerator: List of predictor variables for the numerator model.\n",
    "    :param denominator: List of predictor variables for the denominator model.\n",
    "    :param save_path: Path to save the trained models.\n",
    "    :param pool_models: Strategy for model pooling (\"numerator\", \"denominator\", or \"none\").\n",
    "    :return: Fitted logistic regression model(s).\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=numerator + denominator + [censor_event])  # Remove missing values\n",
    "\n",
    "    # Fit the numerator model (logistic regression)\n",
    "    X_num = sm.add_constant(data[numerator])  # Add intercept\n",
    "    y_num = data[censor_event]  # Assuming 'censored' is a binary column (1 = censored, 0 = not censored)\n",
    "    model_num = sm.Logit(y_num, X_num).fit(disp=False)\n",
    "\n",
    "    # Fit the denominator model if required\n",
    "    if pool_models != \"numerator\":\n",
    "        X_denom = sm.add_constant(data[denominator])\n",
    "        model_denom = sm.Logit(y_num, X_denom).fit(disp=False)\n",
    "    else:\n",
    "        model_denom = None  # Only use the numerator model\n",
    "\n",
    "    # Save models\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump({\"numerator_model\": model_num, \"denominator_model\": model_denom}, f)\n",
    "\n",
    "    return model_num if pool_models == \"numerator\" else (model_num, model_denom)\n",
    "\n",
    "# Define the predictor variables\n",
    "numerator_vars = [\"x2\"]\n",
    "denominator_vars = [\"x2\", \"x1\"]\n",
    "\n",
    "# Define file path for saving the model\n",
    "censor_model_path = os.path.join(trial_itt_dir, \"censor_models.pkl\")\n",
    "\n",
    "# Fit the censor weight model and save it\n",
    "trial_itt.censor_weights = fit_censor_weight_model(\n",
    "    trial_itt.data,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=numerator_vars,\n",
    "    denominator=denominator_vars,\n",
    "    save_path=censor_model_path,\n",
    "    pool_models=\"numerator\"  # Match R code behavior\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(trial_itt.censor_weights.summary())  # Summary of the numerator model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Calculate Weights**\n",
    "\n",
    "Next we need to fit the individual models and combine them into weights. This is done with calculate_weights().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialSequence:\n",
    "    def __init__(self, estimand, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        self.estimand = estimand\n",
    "        self.data = data\n",
    "        self.id_col = id_col\n",
    "        self.period_col = period_col\n",
    "        self.treatment_col = treatment_col\n",
    "        self.outcome_col = outcome_col\n",
    "        self.eligible_col = eligible_col\n",
    "        self.weights = None\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        \"\"\"\n",
    "        Placeholder function for calculating weights.\n",
    "        This should be replaced with actual weight calculation logic.\n",
    "        \"\"\"\n",
    "        self.weights = f\"Weights calculated for {self.estimand} trial\"\n",
    "        return self\n",
    "\n",
    "    def show_weight_models(self):\n",
    "        \"\"\"\n",
    "        Placeholder function to display weight models.\n",
    "        \"\"\"\n",
    "        if self.weights:\n",
    "            print(f\"Weight models for {self.estimand} trial:\", self.weights)\n",
    "        else:\n",
    "            print(f\"No weights calculated for {self.estimand} trial.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        self.estimand = estimand\n",
    "        self.data = data\n",
    "        self.id_col = id_col\n",
    "        self.period_col = period_col\n",
    "        self.treatment_col = treatment_col\n",
    "        self.outcome_col = outcome_col\n",
    "        self.eligible_col = eligible_col\n",
    "        self.switch_weights = None\n",
    "        self.censor_weights = None\n",
    "    \n",
    "    def fit_logistic_regression(self, data, predictor_vars, outcome_var):\n",
    "        \"\"\"Fits a logistic regression model.\"\"\"\n",
    "        X = sm.add_constant(data[predictor_vars])\n",
    "        y = data[outcome_var]\n",
    "        model = sm.Logit(y, X).fit(disp=False)\n",
    "        return model\n",
    "    \n",
    "    def set_switch_weight_model(self, numerator, denominator, save_path):\n",
    "        \"\"\"Fits and saves the switch weight model.\"\"\"\n",
    "        self.switch_weights = {\n",
    "            \"numerator\": self.fit_logistic_regression(self.data, numerator, self.eligible_col),\n",
    "            \"denominator\": self.fit_logistic_regression(self.data, denominator, self.eligible_col)\n",
    "        }\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(self.switch_weights, f)\n",
    "    \n",
    "    def set_censor_weight_model(self, censor_event, numerator, denominator, save_path):\n",
    "        \"\"\"Fits and saves the censor weight model.\"\"\"\n",
    "        self.censor_weights = {\n",
    "            \"numerator\": self.fit_logistic_regression(self.data, numerator, censor_event),\n",
    "            \"denominator\": self.fit_logistic_regression(self.data, denominator, censor_event)\n",
    "        }\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(self.censor_weights, f)\n",
    "    \n",
    "    def calculate_weights(self):\n",
    "        \"\"\"Ensures that weights are properly estimated before proceeding.\"\"\"\n",
    "        if self.switch_weights is None or self.censor_weights is None:\n",
    "            raise ValueError(\"Switch weights and/or censor weights have not been estimated. Run set_switch_weight_model and set_censor_weight_model first.\")\n",
    "        return self  # Allows method chaining\n",
    "    \n",
    "    def show_weight_models(self):\n",
    "        \"\"\"Displays the weight models.\"\"\"\n",
    "        print(\"Switch Weight Models:\")\n",
    "        if self.switch_weights:\n",
    "            print(self.switch_weights[\"numerator\"].summary())\n",
    "        print(\"Censor Weight Models:\")\n",
    "        if self.censor_weights:\n",
    "            print(self.censor_weights[\"numerator\"].summary())\n",
    "\n",
    "# Initialize trial sequences\n",
    "data_censored = pd.read_csv(\"../data/data_censored.csv\")\n",
    "trial_pp = TrialSequence(\"PP\", data_censored, \"id\", \"period\", \"treatment\", \"outcome\", \"eligible\")\n",
    "trial_itt = TrialSequence(\"ITT\", data_censored, \"id\", \"period\", \"treatment\", \"outcome\", \"eligible\")\n",
    "\n",
    "# Define directories\n",
    "trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Fit weight models\n",
    "switch_model_path = os.path.join(trial_pp_dir, \"switch_models.pkl\")\n",
    "trial_pp.set_switch_weight_model([\"age\"], [\"age\", \"x1\", \"x3\"], switch_model_path)\n",
    "\n",
    "censor_model_path = os.path.join(trial_pp_dir, \"censor_models.pkl\")\n",
    "trial_pp.set_censor_weight_model(\"censored\", [\"x2\"], [\"x2\", \"x1\"], censor_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Switch weights and/or censor weights have not been estimated. Run set_switch_weight_model and set_censor_weight_model first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate weights\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trial_pp \u001b[38;5;241m=\u001b[39m trial_pp\u001b[38;5;241m.\u001b[39mcalculate_weights()\n\u001b[0;32m----> 3\u001b[0m trial_itt \u001b[38;5;241m=\u001b[39m \u001b[43mtrial_itt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[80], line 47\u001b[0m, in \u001b[0;36mTrialSequence.calculate_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that weights are properly estimated before proceeding.\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswitch_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcensor_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSwitch weights and/or censor weights have not been estimated. Run set_switch_weight_model and set_censor_weight_model first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Switch weights and/or censor weights have not been estimated. Run set_switch_weight_model and set_censor_weight_model first."
     ]
    }
   ],
   "source": [
    "# Calculate weights\n",
    "trial_pp = trial_pp.calculate_weights()\n",
    "trial_itt = trial_itt.calculate_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch Weight Models:\n",
      "Censor Weight Models:\n",
      "Switch Weight Models:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               eligible   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.09696\n",
      "Time:                        16:39:57   Log-Likelihood:                -356.57\n",
      "converged:                       True   LL-Null:                       -394.86\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.120e-18\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.9822      0.383      5.180      0.000       1.232       2.732\n",
      "age           -0.0692      0.008     -8.152      0.000      -0.086      -0.053\n",
      "==============================================================================\n",
      "Censor Weight Models:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               censored   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        16:39:57   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.4481      0.141    -17.415      0.000      -2.724      -2.173\n",
      "x2             0.4486      0.137      3.278      0.001       0.180       0.717\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show weight models\n",
    "trial_itt.show_weight_models()\n",
    "trial_pp.show_weight_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Specify Outcome Model**\n",
    "\n",
    "Now we can specify the outcome model. Here we can include adjustment terms for any variables in the dataset. The numerator terms from the stabilised weight models are automatically included in the outcome model formula.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrialSequence' object has no attribute 'set_outcome_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply outcome model to trial sequences\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrial_pp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_outcome_model\u001b[49m()\n\u001b[1;32m      3\u001b[0m trial_itt\u001b[38;5;241m.\u001b[39mset_outcome_model(adjustment_terms\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrialSequence' object has no attribute 'set_outcome_model'"
     ]
    }
   ],
   "source": [
    "# Apply outcome model to trial sequences\n",
    "trial_pp.set_outcome_model()\n",
    "trial_itt.set_outcome_model(adjustment_terms=[\"x2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Expand Trials**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 Create Sequence of Trials Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Load or Sample from Expanded Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Fit Marginal Structural Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Inference**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
